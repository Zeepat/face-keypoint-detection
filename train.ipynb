{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import FaceKeypointDataset, transform, train_test_split, train\n",
    "from model.network import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv('data/Annotations/annotations.csv')\n",
    "images_dir = 'data/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FaceKeypointDataset(annotations=annotations_df, \n",
    "                              root_dir=images_dir, \n",
    "                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = train_test_split(dataset, \n",
    "                                                         train_size=0.8, \n",
    "                                                         val_size=0.1, \n",
    "                                                         batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_keypoints = nn.MSELoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:   9%|▊         | 18/206 [00:22<04:09,  1.33s/it, Batch Loss=1.85e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 4566 due to error: image file is truncated (6 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  30%|██▉       | 61/206 [01:20<03:03,  1.27s/it, Batch Loss=8.48e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16413 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image32677.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  33%|███▎      | 69/206 [01:30<02:55,  1.28s/it, Batch Loss=2.12e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16417 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image59010.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  48%|████▊     | 99/206 [02:10<02:25,  1.36s/it, Batch Loss=1.77e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16414 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image59000.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  51%|█████▏    | 106/206 [02:19<02:30,  1.50s/it, Batch Loss=2e+5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16411 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image19281.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  56%|█████▌    | 115/206 [02:31<02:03,  1.36s/it, Batch Loss=1.71e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16412 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image14571.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  67%|██████▋   | 139/206 [03:05<01:32,  1.39s/it, Batch Loss=1.36e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16416 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image59008.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  68%|██████▊   | 141/206 [03:07<01:23,  1.28s/it, Batch Loss=1.32e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16415 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image59004.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 159906.1233 | Val Loss: 144709.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training:  15%|█▌        | 31/206 [00:36<03:49,  1.31s/it, Batch Loss=1.47e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 4566 due to error: image file is truncated (6 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training:  16%|█▌        | 32/206 [00:39<04:44,  1.64s/it, Batch Loss=5.66e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16417 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image59010.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training:  17%|█▋        | 36/206 [00:43<03:29,  1.23s/it, Batch Loss=1.41e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 16411 due to error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\first\\\\Desktop\\\\GithubForSchool\\\\face-keypoint-detection\\\\data\\\\Images\\\\image19281.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcriterion_keypoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcriterion_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbbox_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\first\\Desktop\\GithubForSchool\\face-keypoint-detection\\utils.py:122\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion_keypoints, criterion_bbox, optimizer, train_loader, val_loader, epochs, device, bbox_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_keypoints \u001b[38;5;241m+\u001b[39m bbox_weight \u001b[38;5;241m*\u001b[39m loss_bbox  \u001b[38;5;66;03m# Combine losses\u001b[39;00m\n\u001b[0;32m    121\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 122\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    124\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Update tqdm description with current loss\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, \n",
    "      criterion_keypoints, \n",
    "      criterion_bbox, \n",
    "      optimizer, \n",
    "      train_loader, \n",
    "      val_loader, \n",
    "      epochs=50, \n",
    "      device='cuda', \n",
    "      bbox_weight=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
